<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>simdjson: parse_many</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="doxygen-awesome-sidebar-only-darkmode-toggle.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="logotiny.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">simdjson
   &#160;<span id="projectnumber">3.10.1</span>
   </div>
   <div id="projectbrief">Ridiculously Fast JSON</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_doc_parse_many.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">parse_many </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>An interface providing features to work with files or streams containing multiple small JSON documents. Given an input such as </p><div class="fragment"><div class="line">{&quot;text&quot;:&quot;a&quot;}</div>
<div class="line">{&quot;text&quot;:&quot;b&quot;}</div>
<div class="line">{&quot;text&quot;:&quot;c&quot;}</div>
<div class="line">...</div>
</div><!-- fragment --><p> ... you want to read the entries (individual JSON documents) as quickly and as conveniently as possible. Importantly, the input might span several gigabytes, but you want to use a small (fixed) amount of memory. Ideally, you'd also like the parallelize the processing (using more than one core) to speed up the process.</p>
<h1><a class="anchor" id="autotoc_md86"></a>
Contents</h1>
<ul>
<li><a href="#motivations">Motivations</a></li>
<li><a href="#performance">Performance</a></li>
<li><a href="#how-it-works">How it works</a></li>
<li><a href="#support">Support</a></li>
<li><a href="#api">API</a></li>
<li><a href="#use-cases">Use cases</a></li>
<li><a href="#tracking-your-position">Tracking your position</a></li>
<li><a href="#incomplete-streams">Incomplete streams</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md87"></a>
Motivation</h1>
<p>The main motivation for this piece of software is to achieve maximum speed and offer a better quality of life in parsing files containing multiple small JSON documents.</p>
<p>The JavaScript Object Notation (JSON) <a href="https://tools.ietf.org/html/rfc7159">RFC7159</a> is a handy serialization format. However, when serializing a large sequence of values as an array, or a possibly indeterminate-length or never- ending sequence of values, JSON may be inconvenient.</p>
<p>Consider a sequence of one million values, each possibly one kilobyte when encoded &ndash; roughly one gigabyte. It is often desirable to process such a dataset incrementally without having to first read all of it before beginning to produce results.</p>
<h1><a class="anchor" id="autotoc_md88"></a>
Performance</h1>
<p>The following is a chart comparing the speed of the different alternatives to parse a multiline JSON. The simdjson library provides a threaded and non-threaded <code>parse_many()</code> implementation. As the figure below shows, if you can, use threads, but if you cannot, the unthreaded mode is still fast! <a href="/doc/Multiline_JSON_Parse_Competition.png"><img src="/doc/Multiline_JSON_Parse_Competition.png" alt="Chart.png" class="inline"/></a></p>
<h1><a class="anchor" id="autotoc_md89"></a>
How it works</h1>
<h2><a class="anchor" id="autotoc_md90"></a>
Context</h2>
<p>The parsing in simdjson is divided into 2 stages. First, in stage 1, we parse the document and find all the structural indexes (<code>{</code>, <code>}</code>, <code>]</code>, <code>[</code>, <code>,</code>, <code>"</code>, ...) and validate UTF8. Then, in stage 2, we go through the document again and build the tape using structural indexes found during stage 1. Although stage 1 finds the structural indexes, it has no knowledge of the structure of the document nor does it know whether it parsed a valid document, multiple documents, or even if the document is complete.</p>
<p>Prior to parse_many, most people who had to parse a multiline JSON file would proceed by reading the file line by line, using a utility function like <code>std::getline</code> or equivalent, and would then use the <code>parse</code> on each of those lines. From a performance point of view, this process is highly inefficient, in that it requires a lot of unnecessary memory allocation and makes use of the <code>getline</code> function, which is fundamentally slow, slower than the act of parsing with simdjson <a href="https://lemire.me/blog/2019/06/18/how-fast-is-getline-in-c/">(more on this here)</a>.</p>
<p>Unlike the popular parser RapidJson, our DOM does not require the buffer once the parsing job is completed, the DOM and the buffer are completely independent. The drawback of this architecture is that we need to allocate some additional memory to store our ParsedJson data, for every document inside a given file. Memory allocation can be slow and become a bottleneck, therefore, we want to minimize it as much as possible.</p>
<h2><a class="anchor" id="autotoc_md91"></a>
Design</h2>
<p>To achieve a minimum amount of allocations, we opted for a design where we create only one parser object and therefore allocate its memory once, and then recycle it for every document in a given file. But, knowing that they often have largely varying size, we need to make sure that we allocate enough memory so that all the documents can fit. This value is what we call the batch size. As of right now, we need to manually specify a value for this batch size, it has to be at least as big as the biggest document in your file, but not too big so that it submerges the cached memory. The bigger the batch size, the fewer we need to make allocations. We found that 1MB is somewhat a sweet spot.</p>
<ol type="1">
<li>When the user calls <code>parse_many</code>, we return a <code>document_stream</code> which the user can iterate over to receive parsed documents.</li>
<li>We call stage 1 on the first batch_size bytes of JSON in the buffer, detecting structural indexes for all documents in that batch.</li>
<li>We call stage 2 on the indexes, reading tokens until we reach the end of a valid document (i.e. a single array, object, string, boolean, number or null).</li>
<li>Each time the user calls <code>++</code> to read the next document, we call stage 2 to parse the next document where we left off.</li>
<li>When we reach the end of the batch, we call stage 1 on the next batch, starting from the end of the last document, and go to step 3.</li>
</ol>
<h2><a class="anchor" id="autotoc_md92"></a>
Threads</h2>
<p>But how can we make use of threads if they are available? We found a pretty cool algorithm that allows us to quickly identify the position of the last JSON document in a given batch. Knowing exactly where the end of the batch is, we no longer need for stage 2 to finish in order to load a new batch. We already know where to start the next batch. Therefore, we can run stage 1 on the next batch concurrently while the main thread is going through stage 2. Running stage 1 in a different thread can, in best cases, remove almost entirely its cost and replaces it by the overhead of a thread, which is orders of magnitude cheaper. Ain't that awesome!</p>
<p>Thread support is only active if thread supported is detected in which case the macro SIMDJSON_THREADS_ENABLED is set. You can also manually pass <code>SIMDJSON_THREADS_ENABLED=1</code> flag to the library. Otherwise the library runs in single-thread mode.</p>
<p>You should be consistent. If you link against the simdjson library built for multithreading (i.e., with <code>SIMDJSON_THREADS_ENABLED</code>), then you should build your application with multithreading system (setting <code>SIMDJSON_THREADS_ENABLED=1</code> and linking against a thread library).</p>
<p>A <code>document_stream</code> instance uses at most two threads: there is a main thread and a worker thread. You should expect the main thread to be fully occupied while the worker thread is partially busy (e.g., 80% of the time).</p>
<h1><a class="anchor" id="autotoc_md93"></a>
Support</h1>
<p>Since we want to offer flexibility and not restrict ourselves to a specific file format, we support any file that contains any amount of valid JSON document, <b>separated by one or more character that is considered whitespace</b> by the JSON spec. Anything that is not whitespace will be parsed as a JSON document and could lead to failure.</p>
<p>Whitespace Characters:</p><ul>
<li><b>Space</b></li>
<li><b>Linefeed</b></li>
<li><b>Carriage return</b></li>
<li><b>Horizontal tab</b></li>
<li><b>Nothing</b></li>
</ul>
<p>Some official formats **(non-exhaustive list)**:</p><ul>
<li><a href="https://github.com/ndjson/ndjson-spec">Newline-Delimited JSON (NDJSON)</a></li>
<li><a href="http://jsonlines.org/">JSON lines (JSONL)</a></li>
<li><a href="https://tools.ietf.org/html/rfc7464">Record separator-delimited JSON (RFC 7464)</a> &lt;- Not supported by JsonStream!</li>
<li><a href="https://en.wikipedia.org/wiki/JSON_streaming">More on Wikipedia...</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md94"></a>
API</h1>
<p>See <a href="basics.md#newline-delimited-json-ndjson-and-json-lines">basics.md</a> for an overview of the API.</p>
<h1><a class="anchor" id="autotoc_md95"></a>
Use cases</h1>
<p>From <a href="http://jsonlines.org/examples/">jsonlines.org</a>:</p>
<ul>
<li><p class="startli"><b>Better than CSV</b> ```json ["Name", "Session", "Score", "Completed"] ["Gilbert", "2013", 24, true] ["Alexa", "2013", 29, true] ["May", "2012B", 14, false] ["Deloise", "2012A", 19, true] ``` CSV seems so easy that many programmers have written code to generate it themselves, and almost every implementation is different. Handling broken CSV files is a common and frustrating task. CSV has no standard encoding, no standard column separator and multiple character escaping standards. String is the only type supported for cell values, so some programs attempt to guess the correct types.</p>
<p class="startli">JSON Lines handles tabular data cleanly and without ambiguity. Cells may use the standard JSON types.</p>
<p class="startli">The biggest missing piece is an import/export filter for popular spreadsheet programs so that non-programmers can use this format.</p>
</li>
<li><b>Easy Nested Data</b> ```json {"name": "Gilbert", "wins": [["straight", "7♣"], ["one pair", "10♥"]]} {"name": "Alexa", "wins": [["two pair", "4♠"], ["two pair", "9♠"]]} {"name": "May", "wins": []} {"name": "Deloise", "wins": [["three of a kind", "5♣"]]} ``&lsquo; JSON Lines&rsquo; biggest strength is in handling lots of similar nested data structures. One .jsonl file is easier to work with than a directory full of XML files.</li>
</ul>
<h1><a class="anchor" id="autotoc_md96"></a>
Tracking your position</h1>
<p>Some users would like to know where the document they parsed is in the input array of bytes. It is possible to do so by accessing directly the iterator and calling its <code>current_index()</code> method which reports the location (in bytes) of the current document in the input stream. You may also call the <code>source()</code> method to get a <code>std::string_view</code> instance on the document.</p>
<p>Let us illustrate the idea with code:</p>
<div class="fragment"><div class="line">{C++}</div>
<div class="line">   auto json = R&quot;([1,2,3]  {&quot;1&quot;:1,&quot;2&quot;:3,&quot;4&quot;:4} [1,2,3]  )&quot;_padded;</div>
<div class="line">   simdjson::dom::parser parser;</div>
<div class="line">   simdjson::dom::document_stream stream;</div>
<div class="line">   auto error = parser.parse_many(json).get(stream);</div>
<div class="line">   if (error) { /* do something */ }</div>
<div class="line">   auto i = stream.begin();</div>
<div class="line">   size_t count{0};</div>
<div class="line">   for(; i != stream.end(); ++i) {</div>
<div class="line">       auto doc = *i;</div>
<div class="line">       if (!doc.error()) {</div>
<div class="line">         std::cout &lt;&lt; &quot;got full document at &quot; &lt;&lt; i.current_index() &lt;&lt; std::endl;</div>
<div class="line">         std::cout &lt;&lt; i.source() &lt;&lt; std::endl;</div>
<div class="line">         count++;</div>
<div class="line">       } else {</div>
<div class="line">         std::cout &lt;&lt; &quot;got broken document at &quot; &lt;&lt; i.current_index() &lt;&lt; std::endl;</div>
<div class="line">         return false;</div>
<div class="line">       }</div>
<div class="line">   }</div>
</div><!-- fragment --><p>This code will print: </p><div class="fragment"><div class="line">got full document at 0</div>
<div class="line">[1,2,3]</div>
<div class="line">got full document at 9</div>
<div class="line">{&quot;1&quot;:1,&quot;2&quot;:3,&quot;4&quot;:4}</div>
<div class="line">got full document at 29</div>
<div class="line">[1,2,3]</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md97"></a>
Incomplete streams</h1>
<p>Some users may need to work with truncated streams. The simdjson may truncate documents at the very end of the stream that cannot possibly be valid JSON (e.g., they contain unclosed strings, unmatched brackets, unmatched braces). After iterating through the stream, you may query the <code>truncated_bytes()</code> method which tells you how many bytes were truncated. If the stream is made of full (whole) documents, then you should expect <code>truncated_bytes()</code> to return zero.</p>
<p>Consider the following example where a truncated document (<code>{"key":"intentionally unclosed string</code>) containing 39 bytes has been left within the stream. In such cases, the first two whole documents are parsed and returned, and the <code>truncated_bytes()</code> method returns 39.</p>
<div class="fragment"><div class="line">{C++}</div>
<div class="line">   auto json = R&quot;([1,2,3]  {&quot;1&quot;:1,&quot;2&quot;:3,&quot;4&quot;:4} {&quot;key&quot;:&quot;intentionally unclosed string  )&quot;_padded;</div>
<div class="line">   simdjson::dom::parser parser;</div>
<div class="line">   simdjson::dom::document_stream stream;</div>
<div class="line">   auto error = parser.parse_many(json,json.size()).get(stream);</div>
<div class="line">   if (error) { std::cerr &lt;&lt; error &lt;&lt; std::endl; return; }</div>
<div class="line">   for(auto doc : stream) {</div>
<div class="line">      std::cout &lt;&lt; doc &lt;&lt; std::endl;</div>
<div class="line">   }</div>
<div class="line">   std::cout &lt;&lt; stream.truncated_bytes() &lt;&lt; &quot; bytes &quot;&lt;&lt; std::endl; // returns 39 bytes</div>
</div><!-- fragment --><p>Importantly, you should only call <code>truncated_bytes()</code> after iterating through all of the documents since the stream cannot tell whether there are truncated documents at the very end when it may not have accessed that part of the data yet. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
